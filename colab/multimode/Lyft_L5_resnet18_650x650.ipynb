{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lyft L5 resnet18 650x650.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN62ftkCQVGEWNboSZddBHo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kool7/Lyft_Motion_Prediction_for_Autonomous_Vehicles_2020_Kaggle/blob/master/colab/multimode/Lyft_L5_resnet18_650x650.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW_8VREREWdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25932343-113c-4059-dd1d-e12a206d6476"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3TFM_hxLMoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "\n",
        "os.makedirs('/content/lyft-motion-prediction-autonomous-vehicles/', exist_ok=True)\n",
        "os.chdir('/content/lyft-motion-prediction-autonomous-vehicles/')\n",
        "\n",
        "%cd '/content/lyft-motion-prediction-autonomous-vehicles/'\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX6y-MgmLXLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('/content/lyft-motion-prediction-autonomous-vehicles/scenes/', exist_ok=True)\n",
        "os.chdir('/content/lyft-motion-prediction-autonomous-vehicles/scenes/')\n",
        "\n",
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" --header=\"Cookie: _ga=GA1.3.1723755215.1594569279\" --header=\"Connection: keep-alive\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/19990/1472735/compressed/scenes.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1600842658&Signature=gxy9AEjuHXK%2FOaOplPW%2BtX%2Fy9OzF7AUtdHkPM1yF6mkK0RhFuCDAr%2FnCOJsPXXYWS%2FdujeOu55vFeayz%2FBzm%2FFh8lu1XYhjMWtCThkbAdBH55ZLrVWh5jfq0XmPZ6taGPAeeHic4PZEIP0jnrDFDQaxQpKAqn8JJf07Y79c8VvNhDQRS7%2BH%2FZceHxUADr61dtWXNU6O6As3zKX1nWmi2ePg4TI3AvoqSpttBzMG7p4ycFeGErRLPNOezXDFs%2F5XxABRcktYOXeLqlWeuJA4jLRcWLGT8Kqe8zli2MzSKwfY9DIS%2F0awig6tb3UNXfjmuivzrjYz5F1EFRXeWLn7wFA%3D%3D&response-content-disposition=attachment%3B+filename%3Dscenes.zip\" -c -O 'scenes.zip'\n",
        "!unzip ./scenes.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMTGzIUoLYlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd '/content/lyft-motion-prediction-autonomous-vehicles/scenes/'\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q0iZt5ULcF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%rm -r validate.zarr/\n",
        "%rm -r sample.zarr/\n",
        "%rm scenes.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVrSuk1iLdmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyCJnx-ELfGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('/content/lyft-motion-prediction-autonomous-vehicles/aerial_map/', exist_ok=True)\n",
        "os.chdir('/content/lyft-motion-prediction-autonomous-vehicles/aerial_map/')\n",
        "\n",
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" --header=\"Cookie: _ga=GA1.3.1723755215.1594569279\" --header=\"Connection: keep-alive\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/19990/1472735/compressed/aerial_map.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1600842229&Signature=dMoqJ8V2dAPbooKxro8DhMKZnFlWq21Hw4WHDU32wfDIb1%2FzrQa5lOnI8NuDpWDxMrayJPAlJYGOKcodCjk5g%2B2%2FGpFWc0sO3b%2F3XzaV%2FZ%2BQnu3Ki%2FiRvHzankQOxCnI58V8gnl8nRwZW06eJ3oK9stft4ULwHfACQ6WBiPlTJR9MySPUkLd4gzcOqNqH6fIEC1aimgPX8FZoSr4fLKv94Apxm6U50Urk3ovGZD3nm2fMp4aN5%2BlTXgtuh3XnBO7n2Fb9HA1kygvs5Bgzv1NLUwqMWHjATOPLc5flNpjADSz6Lau8RHL06CzaBD0vb5bYYkjqZQn%2F2e3IQ0YCWPXbQ%3D%3D&response-content-disposition=attachment%3B+filename%3Daerial_map.zip\" -c -O 'aerial_map.zip'\n",
        "!unzip ./aerial_map.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PCkZ7SALglC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%rm -r aerial_map.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTCIRKfNLjo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sft1Vz1Lk7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('/content/lyft-motion-prediction-autonomous-vehicles/semantic_map/', exist_ok=True)\n",
        "os.chdir('/content/lyft-motion-prediction-autonomous-vehicles/semantic_map/')\n",
        "\n",
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" --header=\"Cookie: _ga=GA1.3.1723755215.1594569279\" --header=\"Connection: keep-alive\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/19990/1472735/upload/semantic_map.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1600842323&Signature=syQh6jye4ANNzaRDvWQtQ8MX2h%2BG8Jv4glhJ3gPvW7ECPXjZOE35KVWpsKm5f8pMtyqHetg4mDOtjLYyka%2BPhFpHnBgBEzY65FQujgsU8ojYGOJddYry6U9OLgYJ2dxk%2BECidEEfRhhNa1%2BK9V12x6Zv0eN1mICSRmcX3%2Bl%2Bz075%2BZ1FE2mrEdd0QvIhphzYgXxJZ688MlYzNJOidJvkvMlj2VhtNgmCAPUB7dFBMN5JMwdKkBvlm6JG6GcJHH%2FK7M9SZGQ30l8it0sYRuBAUZtTu3q2RXfQLnmqlD4dbGbv93aqR7Y2U5XQZgHx%2F9qTc33ifCtVjgGoWsP%2FWSXsAA%3D%3D&response-content-disposition=attachment%3B+filename%3Dsemantic_map.zip\" -c -O 'semantic_map.zip'\n",
        "!unzip ./semantic_map.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYwq181LLmQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%rm -r semantic_map.zip\n",
        "%cd ..\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFbtVg0bLosq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## this script transports l5kit and dependencies\n",
        "!pip -q install pymap3d==2.1.0 \n",
        "!pip -q install protobuf==3.12.2 \n",
        "!pip -q install transforms3d \n",
        "!pip -q install zarr \n",
        "!pip -q install ptable\n",
        "\n",
        "!pip -q install --no-dependencies l5kit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmGROHoIH0lu",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI1ply4nLqfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import torch\n",
        "import gc, os, time\n",
        "\n",
        "from torch import Tensor\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.resnet import resnet18, resnet34, resnet50\n",
        "from torchvision.models.densenet import densenet121\n",
        "from tqdm import tqdm\n",
        "from typing import Dict\n",
        "\n",
        "# from l5kit.data import LocalDataManager, ChunkedDataset\n",
        "# from l5kit.dataset import AgentDataset, EgoDataset\n",
        "# from l5kit.rasterization import build_rasterizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBecxAKKL6b-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIR = '/content/lyft-motion-prediction-autonomous-vehicles/'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsTPLBQAL76D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = {\n",
        "    'format_version': 4,\n",
        "    'model_params': {\n",
        "        'model_architecture': 'resnet18',\n",
        "        'history_num_frames': 10,\n",
        "        'history_step_size': 1,\n",
        "        'history_delta_time': 0.1,\n",
        "        'future_num_frames': 50,\n",
        "        'future_step_size': 1,\n",
        "        'future_delta_time': 0.1\n",
        "    },\n",
        "\n",
        "    'raster_params': {\n",
        "        'raster_size': [650, 650],\n",
        "        'pixel_size': [0.5, 0.5],\n",
        "        'ego_center': [0.25, 0.5],\n",
        "        'map_type': 'py_semantic',\n",
        "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
        "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
        "        'dataset_meta_key': 'meta.json',\n",
        "        'filter_agents_threshold': 0.5\n",
        "    },\n",
        "    \n",
        "    'train_data_loader': {\n",
        "        'key': 'scenes/train.zarr',\n",
        "        'batch_size': 32,\n",
        "        'shuffle': True,\n",
        "        'num_workers': 0\n",
        "    },\n",
        "    \n",
        "    'train_params': {\n",
        "        'max_num_steps': 40000,\n",
        "        'checkpoint_every_n_steps': 100,\n",
        "    }\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_umGavNMEV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set env variable for data\n",
        "os.environ[\"L5KIT_DATA_FOLDER\"] = INPUT_DIR\n",
        "dm = LocalDataManager(None)\n",
        "\n",
        "# get config\n",
        "print(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdHn4GxcHx19",
        "colab_type": "text"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqPjivxC0KTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(cfg):\n",
        "\n",
        "  '''\n",
        "  Description\n",
        "  ----------------\n",
        "  Prepare image data by \n",
        "  getting muti-channel tensors\n",
        "  and converting them to rgb images.\n",
        "  It iterates over other agents annotations\n",
        "  and passes the AgentDataset into Pytorch\n",
        "  Dataloader.\n",
        "\n",
        "  Arguments:\n",
        "  cfg -- Configuration file\n",
        "\n",
        "  Returns:\n",
        "  train_dataloader -- Pytorch dataloader\n",
        "  '''\n",
        "  # rasterizer\n",
        "  rasterizer = build_rasterizer(cfg, dm)\n",
        "\n",
        "  # Train dataset/dataloader\n",
        "  train_cfg = cfg[\"train_data_loader\"]\n",
        "  train_zarr = ChunkedDataset(dm.require(train_cfg[\"key\"])).open()\n",
        "  train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
        "  train_dataloader = DataLoader(train_dataset,\n",
        "                                shuffle=train_cfg[\"shuffle\"],\n",
        "                                batch_size=train_cfg[\"batch_size\"],\n",
        "                                num_workers=train_cfg[\"num_workers\"])\n",
        "\n",
        "  return train_dataloader"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CQfiDJHMh_0",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function: Negative Log Likelihood"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sCpPjdaH6AI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def negativeLogLikelihood(ground_truth, prediction, confidences, avails):\n",
        "\n",
        "  '''\n",
        "  Description\n",
        "  -------------------------------\n",
        "  Compute Negative log-likelihood\n",
        "\n",
        "  Arguments:\n",
        "  ground_truth -- array of shape (time)x(2D coords)\n",
        "  prediction -- array of shape (modes)x(time)x(2D coords)\n",
        "  confidences -- array of shape (modes) with a confidence for each mode in each sample\n",
        "  avails -- array of shape (time) with the availability for each gt timestep\n",
        "\n",
        "  Returns:\n",
        "  error -- negative log-likelihood (floating number)\n",
        "  '''\n",
        "\n",
        "  assert len(prediction.shape) == 4, f\"expected 4D (BxMxTxC) array for pred, got {pred.shape}\"\n",
        "  batch_size, num_modes, future_len, num_coords = prediction.shape\n",
        "\n",
        "  assert ground_truth.shape == (batch_size, future_len, num_coords), f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
        "  assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
        "  assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
        "  assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
        "\n",
        "  # assert all data are valid\n",
        "  assert torch.isfinite(prediction).all(), \"invalid value found in pred\"\n",
        "  assert torch.isfinite(ground_truth).all(), \"invalid value found in gt\"\n",
        "  assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
        "  assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
        "\n",
        "  ground_truth = torch.unsqueeze(ground_truth, 1)\n",
        "  avails = avails[:, None, :, None]\n",
        "  error = torch.sum(((ground_truth - prediction) * avails) ** 2, dim = -1)\n",
        "\n",
        "  with np.errstate(divide='ignore'):\n",
        "    error = torch.log(confidences) - 0.5 * torch.sum(error, dim = -1)\n",
        "\n",
        "  max_value = error.max()\n",
        "  error = - torch.log(torch.sum(torch.exp(error - max_value), dim = -1, keepdim = True)) - max_value\n",
        "  return torch.mean(error)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfS5aSaxEZVz",
        "colab_type": "text"
      },
      "source": [
        "# Model: resnet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxmlqQIAM4X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LyftMultiModel(nn.Module):\n",
        "  \n",
        "  def __init__(self, cfg: Dict, num_modes=3):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    architecture = cfg[\"model_params\"][\"model_architecture\"]\n",
        "    backbone = eval(architecture)(pretrained=True, progress=True)\n",
        "    self.backbone = backbone\n",
        "\n",
        "    num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
        "    num_in_channels = 3 + num_history_channels\n",
        "\n",
        "    self.backbone.conv1 = nn.Conv2d(\n",
        "        num_in_channels,\n",
        "        self.backbone.conv1.out_channels,\n",
        "        kernel_size=self.backbone.conv1.kernel_size,\n",
        "        stride=self.backbone.conv1.stride,\n",
        "        padding=self.backbone.conv1.padding,\n",
        "        bias=False,\n",
        "    )\n",
        "    \n",
        "    if architecture == \"resnet50\":\n",
        "        backbone_out_features = 2048\n",
        "    else:\n",
        "        backbone_out_features = 512\n",
        "\n",
        "    # X, Y coords for the future positions (output shape: batch_sizex50x2)\n",
        "    self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
        "    num_targets = 2 * self.future_len\n",
        "\n",
        "    # You can add more layers here.\n",
        "    self.head = nn.Sequential(\n",
        "        # nn.Dropout(0.2),\n",
        "        nn.Linear(in_features=backbone_out_features, out_features=4096),\n",
        "    )\n",
        "\n",
        "    self.num_preds = num_targets * num_modes\n",
        "    self.num_modes = num_modes\n",
        "\n",
        "    self.logit = nn.Linear(4096, out_features=self.num_preds + num_modes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \n",
        "    x = self.backbone.conv1(x)\n",
        "    x = self.backbone.bn1(x)\n",
        "    x = self.backbone.relu(x)\n",
        "    x = self.backbone.maxpool(x)\n",
        "\n",
        "    x = self.backbone.layer1(x)\n",
        "    x = self.backbone.layer2(x)\n",
        "    x = self.backbone.layer3(x)\n",
        "    x = self.backbone.layer4(x)\n",
        "\n",
        "    x = self.backbone.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    x = self.head(x)\n",
        "    x = self.logit(x)\n",
        "\n",
        "    # pred (batch_size)x(modes)x(time)x(2D coords)\n",
        "    # confidences (batch_size)x(modes)\n",
        "    bs, _ = x.shape\n",
        "    pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
        "    pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
        "    assert confidences.shape == (bs, self.num_modes)\n",
        "    confidences = torch.softmax(confidences, dim=1)\n",
        "    return pred, confidences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA0Oa7qTM_hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(data, model, device, criterion = negativeLogLikelihood):\n",
        "  inputs = data[\"image\"].to(device)\n",
        "  target_availabilities = data[\"target_availabilities\"].to(device)\n",
        "  targets = data[\"target_positions\"].to(device)\n",
        "\n",
        "  # Forward pass\n",
        "  preds, confidences = model(inputs)\n",
        "  loss = criterion(targets, preds, confidences, target_availabilities)\n",
        "  return loss, preds"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPxn0XkuNEmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ==== INIT MODEL\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LyftMultiModel(cfg)\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWspm801NGoh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a19e0810-6322-42f8-8db1-3948a110eaf2"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGBZx3HWam4_",
        "colab_type": "text"
      },
      "source": [
        "# Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdkHKnNDNH2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WEIGHT_FILE = '/content/drive/My Drive/Kaggle/Lyft L5 Motion Prediction/resnet18_450x450_model_state_1999.pth'\n",
        "# checkpoint = torch.load(WEIGHT_FILE, map_location=device)\n",
        "# epoch = checkpoint['epoch']\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFrGZGD-aje-",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nqczySrPdp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(cfg, device, model, optimizer):\n",
        "\n",
        "  losses_train = []\n",
        "  iterations = []\n",
        "  metrics = []\n",
        "  times = []\n",
        "\n",
        "  print('Getting Dataloader...')\n",
        "  train_dataloader = get_data(cfg)\n",
        "\n",
        "  progress_bar = tqdm(range(cfg['train_params']['max_num_steps']))\n",
        "\n",
        "  start = time.time()\n",
        "  for i in progress_bar:\n",
        "    try:\n",
        "      data = next(iter(train_dataloader))\n",
        "    except StopIteration:\n",
        "      data = next(iter(train_dataloader))\n",
        "\n",
        "    print('Training...')\n",
        "    model.train()\n",
        "    torch.set_grad_enabled(True)\n",
        "\n",
        "    loss, _ = forward(data, model, device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses_train.append(loss.item())\n",
        "\n",
        "    if i % cfg['train_params']['checkpoint_every_n_steps'] == 0:\n",
        "      torch.save({'epoch': i + 1,\n",
        "                  'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict()},\n",
        "                  f'/content/drive/My Drive/Kaggle/Lyft L5 Motion Prediction/resnet18_650x650_model_state_{i}.pth')\n",
        "\n",
        "      iterations.append(i)\n",
        "      metrics.append(np.mean(losses_train))\n",
        "      times.append((time.time()-start)/60)\n",
        "    progress_bar.set_description(f'loss: {loss.items()} loss_avg: {np.mean(losses_train)}')\n",
        "\n",
        "  results = pd.DataFrame({'iterations': iterations, 'metrics (avg)': metrics, 'elapsed_time (mins)': times})\n",
        "  results.to_csv(f'/content/drive/My Drive/Kaggle/train_metrics_resnet18_40000.csv', index = False)\n",
        "  print(f\"Total training time is {(time.time()-start)/60} mins\")\n",
        "  print(results.head())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx-Cr-sw12_t",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qHE-8M414DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}